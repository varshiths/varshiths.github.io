<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Varshith Sreeramdass</title>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
        <meta property="og:url" content="https://varshiths.github.io" />
	    <meta property="og:title" content="Varshith Sreeramdass" />
	    <meta property="og:image" content="https://varshiths.github.io/img/me_2023.jpg" />
	    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	    <meta name="author" content="Varshith Sreeramdass">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="css/style.css">
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <link href='https://fonts.googleapis.com/css?family=EB+Garamond' rel='stylesheet' type='text/css'>
    </head>
    <body>
        <div class="container mt-5">
            <div class="row mb-3">
                <div class="col">
                    <h1>Varshith Sreeramdass</h1>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-4 col-md-6 order-0 order-xs-0 order-sm-0 order-md-1 order-lg-1">
                    <div class="card mb-3">
                        <img class="card-img-top" src="img/me_2023.jpg" alt="Varshith Sreeramdass">
                        <div class="card-body">
                            <h5 class="card-title">
                                <b>Varshith Sreeramdass</b>
                            </h5>
                            <p class="card-text">
                                MSCS 2022-2024
                                </br>
                                Georgia Institute of Technology
                                </br>
                                Atlanta, US
                                </br>
                                </br>
                                Email: vsreeramdass@gatech.edu
                            </p>
                        </div>
                    </div>
                </div>
                <div class="col-lg-8 col-md-6 order-1 order-xs-1 order-sm-1 order-md-0 order-lg-0">
                    <p>
                        Hi! I'm a Master's student in Computer Science at <a href="https://www.gatech.edu/">Georgia Tech</a>, specializing in Computational Perception and Robotics.
                    </p>
                    <p>
                        My research interests are in Robot Learning and Human-Robot Interaction. More specifically, I am interested in enabling efficient sensorimotor learning of robots acting in the real human world. I am currently a part of the <a href="https://core-robotics.gatech.edu/">CORE Robotics Lab</a>, working on creating robot agents that can effectively partner with humans in racquet sports.
                    </p>
                    <p>
                        I was previously a Research Engineer in the <a href="https://www.honda.co.jp/robotics" target="_blank">robotics divison</a> of Honda R&D working on Deep Reinforcement Learning for Manipulation. I completed my undergrad from <a href="https://www.iitb.ac.in" target="_blank">IIT Bombay</a>, majoring in Computer Science and Engineering, where I worked on Out-of-distribution detection and Domain Adaptation in NLP with <a href="https://www.cse.iitb.ac.in/~sunita/" >Prof. Sunita Sarawagi</a> and <a href="https://www.cse.iitb.ac.in/~soumen/">Prof. Soumen Chakrabarti</a>.
                    </p>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <p>
                        Links:
                        [<a href="res/CV.pdf" target="_blank">CV</a>] [<a href="https://github.com/varshiths" target="_blank">Github</a>] [<a href="https://www.linkedin.com/in/vsreeramdass/" target="_blank">LinkedIn</a>]
                    </p>
                </div>
            </div>
            <hr>
            <div class="row" id="publications">
                <div class="col">
                    <h2>Projects</h2>
                    <ul class="pl">
                        <li>
                            <b>Data-driven DRL for Dexterous InHand Manipulation</b>
                            <br/>
                            <b>Varshith Sreeramdass</b>,
                            Akinobu Hayashi and
                            Tadaaki Hasegawa.
                            <br/>
                            Frontier Robotics, Honda R&D, 2021.
                            <br/>
                            [<a href="#" onclick="$('#honda_1_data_rl').toggle();return false;">Abstract</a>]
                            [<a href="https://response.jp/article/2021/09/30/349938.html" target="_blank">Press Release</a>]
                            [<a href="https://www.youtube.com/watch?v=tS9LL2oVbYI" target="_blank">Video</a>]
                            <div id="honda_1_data_rl" class="abstract" style="display:true;">
                                <div class="row align-items-center">
                                    <div class="col-md-3 text-center my-auto">
                                        <img src="img/proto2_rl.jpg" alt="proto2_rl">
                                    </div>
                                    <div class="col-md-9">
                                        <p>
                                        Learning dexterous manipulation directly on real robots is considerably difficult to do from scratch due to physical constraints. 
                                        Applying Sim-to-Real is not straight forward and resource intensive. 
                                        In this work, we employ data-driven reinforcement learning algorithms (DAPG, AWAC) to bootstrap learning with expert and suboptimal demos.
                                        This ongoing work is currently able to achieve transitions among precision, tripod and power grasps with robustness towards object initialization noise.
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <b>Hierarchical RL of Motor Primitive based Robotic Manipulation Control</b>
                            <br/>
                            <b>Varshith Sreeramdass</b>,
                            Takayuki Osa and
                            Akinobu Hayashi.
                            <br/>
                            Frontier Robotics, Honda R&D, 2021.
                            <br/>
                            [<a href="#" onclick="$('#honda_dmp').toggle();return false;">Abstract</a>]
                            <div id="honda_dmp" class="abstract" style="display:true;">
                                <div class="row align-items-center">
                                    <div class="col-md-3 text-center my-auto">
                                        <img src="img/pmdmp.png" alt="proto2_rl">
                                    </div>
                                    <div class="col-md-9">
                                        <p>
                                            Exploration efficiency is a persistent problem in Robot Learning. Structure can be induced into exploration by using control systems such as Dynamic Motion Primitives (DMPs) as low level policies, and reasoning over/exploring in goal and duration spaces with gating policies. This work attempts to apply such Motor Primitive based Hierarchical Reinforcement Learning to tasks dealing with Maze Navigation, Box Pushing and InHand Manipulation. We also break the abstraction of the primitive being a single high level step, to study primitive interruption heuristics, duration inference mechanisms, optimization of inference costs, local planning and utilization of sub primitive trajectory information for frequent network updates.
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <b>Domain Adaptation of Cloud NLP Services through Word Substitutions</b>
                            <br/>
                            <b>Varshith Sreeramdass</b>,
                            Vihari Piratla,
                            Sunita Sarawagi and
                            Soumen Chakrabarti.
                            <br/>
                            <b>B. Tech. Thesis (Part II)</b>, IIT Bombay, 2019.
                            <br/>
                            [<a href="#" onclick="$('#btp_2_cloud_nlp_abstract').toggle();return false;">Abstract</a>]
                            [<a href="res/BTP_II.pdf" target="_blank">Report</a>]
                            [<a href="res/BTP_II_Survey.pdf" target="_blank">Survey</a>]
                            <div id="btp_2_cloud_nlp_abstract" class="abstract" style="display:true;">
                                <div class="row">
                                    <div class="col-md-3 text-center my-auto">
                                        <img src="img/cloud_rephrase.png" alt="cloud_rephrase">
                                    </div>
                                    <div class="col-md-9">
                                        <p>
                                        Several cloud services are available which perform natural language tasks 
                                        like sentiment classification, named entity recognition, dependency parsing, fine type tagging, etc. 
                                        While these services are trained on a large diverse dataset 
                                        encompassing a large number of domains, the performance of the service 
                                        on a specific narrow domain relevant to the application may be sub par. 
                                        For the tasks of sentiment classification and NER, 
                                        this work attempts to adapt sentences in the target domain 
                                        to the domain of the service model, to improve 
                                        the performance of the service model, through word substitutions.
                                        </p>
                                        <p>
                                        Additionally, this project also surveyed in depth, methods to learn an optimal active learner using Reinforcement Learning.
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <b>Out-of-Distribution Image Detection with Deep Neural Networks</b>
                            <br/>
                            <b>Varshith Sreeramdass</b> and
                            Sunita Sarawagi.
                            <br/>
                            <b>B. Tech. Thesis (Part I)</b>, IIT Bombay, 2019.
                            <br/>
                            [<a href="#" onclick="$('#btp_1_ood').toggle();return false;">Abstract</a>]
                            [<a href="res/BTP_I.pdf" target="_blank">Report</a>]
                            <div id="btp_1_ood" class="abstract" style="display:true;">
                                <div class="row">
                                    <div class="col-md-3 text-center my-auto">
                                        <img src="img/odin.png" alt="ood">
                                        <p>Image: <a href="https://arxiv.org/pdf/1706.02690.pdf">Liang, et. al., 2017</a></p>
                                    </div>
                                    <div class="col-md-9">
                                        <p>
                                        Out-of-distribution detection is vital in the deployment of Deep Neural Networks
                                        in practical applications. Several methods exist that range from temperature scaling
                                        of logits to model ensembles.  This work surveys extensively existing
                                        methods for out-of-distribution detection that either use features extracted by
                                        pre-trained models, or propose minimal modifications to the framework, analyses
                                        their performance, shortcomings and proposes a few simple enhancements that produce comparable results.
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <b>Augmenting Scene Graph Generation with Knowledge from Corpora</b>
                            <br/>
                            <b>Varshith Sreeramdass</b>,
                            Amrita Saha and
                            Soumen Chakrabarti.
                            <br/>
                            Independent Study Under Faculty, IIT Bombay, Spring 2019.
                            <br/>
                            [<a href="#" onclick="$('#r_and_d_proj_augmenting').toggle();return false;">Abstract</a>]
                            [<a href="https://github.com/varshiths/scg-augmented/blob/master/REPORT.md" target="_blank">Report</a>]
                            <div id="r_and_d_proj_augmenting" class="abstract" style="display:true;">
                                <div class="row">
                                    <div class="col-md-3 text-center my-auto">
                                        <img src="img/lk_distill.png" alt="lk_distill">
                                        <p>Image: <a href="https://arxiv.org/abs/1707.09423">Yu, et al., 2017</a></p>    
                                    </div>
                                    <div class="col-md-9">
                                        <p>
                                        Scene graph generation is vital to structuring the information in a visual scene. 
                                        It is also one of the most challenging tasks in computer vision, requiring an enormous amount of data to learn from. 
                                        The task can thus benefit from side information, knowledge that is not necessarily in the form of image annotations, 
                                        but a distribution over the edges of a scene graph obtained from the likes of a relevant knowledge base or a text corpus.
                                        This work attempts to study the method of Linguistic Knowledge Distillation (Yu, Ruichi, et al., 2017), and enhance scene graph generation 
                                        by augmenting with information from various text corpus describing visual scenes, objects and their spatial relationships.
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </li>
                        <br/>
                        <li>
                            <b>Sign Language Synthesis with Adversarial Styling</b>
                            <br/>
                            <b>Varshith Sreeramdass</b> and
                            Heike Brock.
                            <br/>
                            Summer Internship, HRI-JP, Summer 2018.
                            <br/>
                            [<a href="#" onclick="$('#intern_hrijp_sls').toggle();return false;">Abstract</a>]
                            [<a href="res/HRIJP.pdf" target="_blank">Report</a>]
                            [<a href="https://github.com/varshiths/pr-scgan" target="_blank">Code</a>]
                            <div id="intern_hrijp_sls" class="abstract" style="display:true;">
                                <div class="row">
                                    <div class="col-md-3 text-center my-auto">
                                        <img src="img/jsl_char.png" alt="jsl_char">
                                    </div>
                                    <div class="col-md-9">
                                        <p>
                                        To enable communication between those that are ignorant and fluent in sign langauge,
                                        seq-to-seq models that generate joint trajectories of virtual characters from sign-language tokens can be leveraged.
                                        However, such generated motion tends to feel robotic and lacks natural-human variability.
                                        The work attempts to build upon such models to enable variation in style.
                                        The model is coupled with style parameters that
                                        are learnt in an unsupervised manner using a GAN approach.
                                        While the model fails in generating reliable motion usable for 
                                        communication, the work does explore a representations for motion capture
                                        data and invalidate using certain types.
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </li>
                        <br/>
                    </ul>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col">
                    <h2>Miscellaneous</h2>
                    <ul>
                        <li>
                            In my free time, I like to try new food, listen to rock music, visit art museums and (occasionally) hike.
                        </li>
                        <li>
                            I speak English, the Rayalaseema dialect of Telugu, Hindi and N3 Japanese.
                        </li>
                        <li>
                            I borrowed the template for this website from <a href="https://nelsonliu.me/"
                            target="_blank">Nelson Liu</a>'s homepage.
                        </li>
                    </ul>
                </div>
            </div>
            <footer class="pt-2 my-md-2 pt-md-2 border-top">
                <div class="row justify-content-center">
                    <div class="col-6 col-md text-left align-self-center">
                        <p class="h5 text-muted">
                            Last updated in November 2022.
                        </p>
                    </div>
                    <div class="col-6 col-md text-right">
                        <a href="https://www.iitb.ac.in" class="image-link">
                            <img class="mr-4" src="img/iitb.png" alt="IITB logo." height="75">
                        </a>
                        <a href="https://www.honda.co.jp/robotics" class="image-link">
                            <img src="img/honda.png" alt="Honda logo." height="75">
                        </a>
                        <a href="https://ic.gatech.edu/" class="image-link">
                            <img src="img/gt.png" alt="GaTech logo." height="75">
                        </a>
                    </div>
                </div>
            </footer>
        </div>
    </body>
</html>
